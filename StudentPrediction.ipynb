{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskhRKMdYHD6"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD4YlQ1WngEK"
      },
      "source": [
        "from random import seed\n",
        "from random import randrange\n",
        "from random import random\n",
        "from csv import reader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from math import exp\n",
        "import operator\n",
        "import time\n",
        "\n",
        "a =''#predictData path\n",
        "r = list() # results\n",
        "network = list() #initialize_network as global\n",
        "\n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row[1:])\n",
        "\treturn dataset\n",
        "\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        "\n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup\n",
        "\n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tstats = [[min(column), max(column)] for column in zip(*dataset)]\n",
        "\treturn stats\n",
        "\n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)-1):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        "\n",
        "# Split a dataset into k folds\n",
        "def cross_validation_split(dataset, n_folds):\n",
        "\tdataset_split = list()\n",
        "\tdataset_copy = list(dataset)\n",
        "\tfold_size = int(len(dataset) / n_folds)\n",
        "\tfor i in range(n_folds):\n",
        "\t\tfold = list()\n",
        "\t\twhile len(fold) < fold_size:\n",
        "\t\t\tindex = randrange(len(dataset_copy))\n",
        "\t\t\tfold.append(dataset_copy.pop(index))\n",
        "\t\tdataset_split.append(fold)\n",
        "\treturn dataset_split\n",
        "\n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n",
        "\n",
        "# Evaluate an algorithm using a cross validation split\n",
        "def evaluate_algorithm(dataset, n_folds, *args):\n",
        "\tfolds = cross_validation_split(dataset, n_folds)\n",
        "\tscores = list()\n",
        "\tc=0\n",
        "\tfor fold in folds:\n",
        "\t\ttrain_set = list(folds)\n",
        "\t\ttrain_set.remove(fold)\n",
        "\t\ttrain_set = sum(train_set, [])\n",
        "\t\ttest_set = list()\n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttest_set.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\t\tif c == 1:\n",
        "\t\t\tv = 'testing model '\n",
        "\t\telif c == 0:\n",
        "\t\t\tv = 'training model'\n",
        "\t\tpredicted = back_propagation(train_set, test_set, *args ,v)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\taccuracy = accuracy_metric(actual, predicted)\n",
        "\t\tscores.append(accuracy)\n",
        "\t\tc = c+1\n",
        "\treturn scores\n",
        "\n",
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation\n",
        "\n",
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + exp(-activation))\n",
        "\n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "    inputs = row\n",
        "    for layer in network:\n",
        "        new_inputs = []\n",
        "        for neuron in layer:\n",
        "            activation = activate(neuron['weights'], inputs)\n",
        "            neuron['output'] = transfer(activation)\n",
        "            new_inputs.append(neuron['output'])\n",
        "        inputs = new_inputs\n",
        "    return inputs\n",
        "\n",
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)\n",
        "\n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        "\n",
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n",
        "\n",
        "# Train a network for a fixed number of epochs\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs,v):\n",
        "\twith tqdm(total = len(train)*n_epoch, desc= v , bar_format = \"{l_bar}{bar} [time left: {remaining} ]\") as pbar:\n",
        "\t\tfor epoch in range(n_epoch):\n",
        "\t\t\tfor row in train:\n",
        "\t\t\t\toutputs = forward_propagate(network, row)\n",
        "\t\t\t\texpected = [0 for i in range(n_outputs)]\n",
        "\t\t\t\texpected[row[-1]] = 1\n",
        "\t\t\t\tbackward_propagate_error(network, expected)\n",
        "\t\t\t\tupdate_weights(network, row, l_rate)\n",
        "\t\t\t\tpbar.update(1)\n",
        "\n",
        "# Initialize a network\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        "\treturn network\n",
        "\n",
        "# Make a prediction with a network\n",
        "def predict(network, row):\n",
        "\toutputs = forward_propagate(network, row)\n",
        "\treturn outputs.index(max(outputs))\n",
        "\n",
        "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
        "def back_propagation(train, test, l_rate, n_epoch, n_hidden,v):\n",
        "  n_inputs = len(train[0]) - 1\n",
        "  n_outputs = len(set([row[-1] for row in train]))\n",
        "  global network\n",
        "  network = initialize_network(n_inputs, n_hidden, n_outputs)\n",
        "  train_network(network, train, l_rate, n_epoch, n_outputs,v)\n",
        "  predictions = list()\n",
        "  for row in test:\n",
        "    prediction = predict(network, row)\n",
        "    predictions.append(prediction)\n",
        "  return(predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfhEURQfnmHV"
      },
      "source": [
        "#main function\n",
        "def main():\n",
        "    #loading the datasets\n",
        "    data3 = load_csv('p3.csv')\n",
        "    data2 = load_csv('p2.csv')\n",
        "    data1 = load_csv('p1.csv')\n",
        "    #removing the labels fo every dataset\n",
        "    data1.pop(0)\n",
        "    data2.pop(0)\n",
        "    data3.pop(0)\n",
        "\n",
        "    #converting into float\n",
        "    #for data 1\n",
        "    for i in range(len(data1[0])-1):\n",
        "        str_column_to_float(data1,i)\n",
        "    #for data 2\n",
        "    for i in range(len(data2[0])-1):\n",
        "        str_column_to_float(data2,i)\n",
        "    #for data 3\n",
        "    for i in range(len(data3[0])-1):\n",
        "        str_column_to_float(data3,i)\n",
        "\n",
        "    #converting class label column in to int\n",
        "    #for data 1\n",
        "    str_column_to_int(data1,len(data1[0])-1)\n",
        "    #for data 2\n",
        "    str_column_to_int(data2,len(data2[0])-1)\n",
        "    #for data 3\n",
        "    str_column_to_int(data3,len(data3[0])-1)\n",
        "\n",
        "    #normalize input variables\n",
        "    #for data 1\n",
        "    minmax1 = dataset_minmax(data1)\n",
        "    normalize_dataset(data1,minmax1)\n",
        "    #for data 2\n",
        "    minmax2 = dataset_minmax(data2)\n",
        "    normalize_dataset(data2,minmax2)\n",
        "    #for data 3\n",
        "    minmax3 = dataset_minmax(data3)\n",
        "    normalize_dataset(data3,minmax3)\n",
        "\n",
        "    #evaluate algorithm variables\n",
        "    n_folds =2\n",
        "    l_rate = 0.4\n",
        "    n_epoch =500\n",
        "    n_hidden =5\n",
        "\n",
        "    # options\n",
        "    c = int(input(\"enter the choice \\n0) predicting for more.\\n1) predicting for a single.\\n\\n   \"))\n",
        "    if c == 0:\n",
        "    \tflag = 0\n",
        "    elif c==1:\n",
        "        flag = 1\n",
        "    else:\n",
        "        print('choice a valid option:')\n",
        "        main()\n",
        "\n",
        "    global a\n",
        "    if flag == 0:\n",
        "        a = input(\"enter the file name for predicting:\")\n",
        "        dataset = pd.read_csv(a)\n",
        "        dataset['Marks']=dataset['Marks'].replace(\"ABS\",0)\n",
        "        dataset['Marks2']=dataset['Marks2'].replace(\"ABS\",0)\n",
        "        dataset['Marks']=dataset['Marks'].replace(\"\",0)\n",
        "        dataset['Marks2']=dataset['Marks2'].replace(\"\",0)\n",
        "        d1 = dataset[[\"Marks\",\"Marks2\",\"comp\"]]\n",
        "\n",
        "        dataset.drop(dataset.columns[[0,1,3,8]], axis = 1, inplace = True)\n",
        "        try:\n",
        "            d1[[\"Marks\", \"Marks2\", \"comp\"]] = d1[[\"Marks\",\"Marks2\",\"comp\"]].apply(pd.to_numeric)\n",
        "            d1['Marks2'] = np.where( (d1['Marks'] >= d1['Marks2']),(((2*d1['Marks'] + (d1['Marks2']/2)) * 40) / 100),(((2*d1['Marks2'] + (d1['Marks']/2)) * 40) / 100) )\n",
        "            d1['comp'] = (d1['Marks2']/40)*30 + d1['comp']\n",
        "            dataset['Marks2'] = d1['Marks2']\n",
        "            dataset['comp'] = d1['comp']\n",
        "        except:\n",
        "            print('Student Acadamic prediction')\n",
        "\n",
        "        dataset.to_csv('pd3.csv')\n",
        "        dataset.drop(dataset.columns[[4,21]], axis = 1, inplace =True)\n",
        "\n",
        "        dataset.to_csv('pd2.csv')\n",
        "\n",
        "        dataset.drop(dataset.columns[[3,19]], axis = 1, inplace = True)\n",
        "\n",
        "        dataset.to_csv('pd1.csv')\n",
        "    else:\n",
        "        h = list()\n",
        "        j = ['Course_code','sem','Student_id','age','Marks','Marks2','comp','health_issues','sports','events','inter_score','school','social_acc','age/sem','batch','gender','late_assSub','organizing','coding_skill','speaking_skill','backlogs','att1','att2','att3']\n",
        "        for i in j:\n",
        "            if i == 'age/sem':\n",
        "                h.append(h[3]/h[1])\n",
        "            elif i == 'Course_code' or i == 'Student_id':\n",
        "                print('enter field ',i,': ')\n",
        "                h.append(input())\n",
        "            else:\n",
        "                print('enter field ',i,': ')\n",
        "                h.append(float(input()))\n",
        "        h.pop(0)\n",
        "        h.pop(1)\n",
        "\n",
        "    global r\n",
        "    # phase 1\n",
        "    print('\\n\\nbuilding phase1 model:\\n')\n",
        "    scores = evaluate_algorithm(data1,n_folds,l_rate, n_epoch, n_hidden)\n",
        "    print(\"scores: %s\" %scores)\n",
        "    print(\"mean Acuracy: %.3f%%\" % (sum(scores)/float(len(scores))))\n",
        "\n",
        "    if flag ==0:\n",
        "        #loading predict data phase 1\n",
        "        pdata = load_csv('pd1.csv')\n",
        "        pdata.pop(0)\n",
        "        #print(pdata)\n",
        "\n",
        "    \t#converting in to float\n",
        "    \t#for data 1\n",
        "        for i in range(len(pdata[0])-1):\n",
        "            str_column_to_float(pdata,i)\n",
        "\n",
        "        #normalize data\n",
        "        normalize_dataset(pdata,minmax1)\n",
        "\n",
        "        r1 = list()\n",
        "\n",
        "        for i in pdata:\n",
        "            k = predict(network,i)\n",
        "            r1.append(k)\n",
        "        r = r1\n",
        "        print(r1)\n",
        "    else:\n",
        "        u = h[:-2]\n",
        "        print(predict(network,u))\n",
        "    \t#print(predict(network,[0.0, 0.5, 0.5671641791044776, 0.0, 0.9, 0.8020833333333334, 0.0, 1.0, 0.0, 0.5128205128205128, 0.1111111111111111, 1.0, 0.7777777776049382, 0.0, 1.0, 0.15, 0.0, 0.0, 0.0, 0.0, 0.9545454545454546, None]))\n",
        "\n",
        "    while(1):\n",
        "        o = input(\"enter c to continue or enter x to exit\\n\\t\")\n",
        "        if o == 'c' or o == 'C':\n",
        "            print(\"\\nphase 2 will include marks and attendance up to mid term 2 \")\n",
        "            break\n",
        "        elif o == 'x' or o == 'X':\n",
        "            return\n",
        "\n",
        "    #phase 2\n",
        "    print('\\nbuilding phase2 model:\\n')\n",
        "    scores = evaluate_algorithm(data2,n_folds,l_rate, n_epoch, n_hidden)\n",
        "    print(\"scores: %s\" %scores)\n",
        "    print(\"mean Acuracy: %.3f%%\" % (sum(scores)/float(len(scores))))\n",
        "\n",
        "    if flag == 0:\n",
        "        #loading predict data phase 2\n",
        "        pdata = load_csv('pd2.csv')\n",
        "        pdata.pop(0)\n",
        "\n",
        "    \t#converting into float\n",
        "        #for data 2\n",
        "        for i in range(len(pdata[0])-1):\n",
        "            str_column_to_float(pdata,i)\n",
        "\n",
        "        #normalize data 2 using minmax 2\n",
        "        normalize_dataset(pdata,minmax2)\n",
        "\n",
        "        r2 = list()\n",
        "\n",
        "        for i in pdata:\n",
        "            k = predict(network,i)\n",
        "            r2.append(k)\n",
        "        r = r2\n",
        "        print(r2)\n",
        "    else:\n",
        "        u = h[:-1]\n",
        "        print(predict(network,u))\n",
        "\n",
        "        #print(predict(network,[0.0, 0.5, 0.5671641791044776, 0.0, 0.9, 0.8020833333333334, 0.0, 1.0, 0.0, 0.5128205128205128, 0.1111111111111111, 1.0, 0.7777777776049382, 0.0, 1.0, 0.15, 0.0, 0.0, 0.0, 0.0, 0.9545454545454546, 0.9745454545454546, None]))\n",
        "\n",
        "    while(1):\n",
        "        o = input('enter c to continue or enter x to exit\\n\\t')\n",
        "        if o == 'c' or o == 'C':\n",
        "            print('\\nphase 3 will include marks and attendance upto end of the semester attendance')\n",
        "            break\n",
        "        elif o == 'x' or o == 'X':\n",
        "            return\n",
        "\n",
        "    #phase 3\n",
        "    print('\\nbuilding phase3 model:\\n')\n",
        "    scores = evaluate_algorithm(data3,n_folds,l_rate, n_epoch, n_hidden)\n",
        "    print(\"scores: %s\" %scores)\n",
        "    print(\"mean Acuracy: %.3f%%\" % (sum(scores)/float(len(scores))))\n",
        "\n",
        "    if flag == 0:\n",
        "        #loading predict data phase 3\n",
        "        pdata = load_csv('pd3.csv')\n",
        "        pdata.pop(0)\n",
        "        #print(pdata)\n",
        "\n",
        "        #coverting into float for data 3\n",
        "        for i in range(len(pdata[0])-1):\n",
        "        \tstr_column_to_float(pdata,i)\n",
        "\n",
        "        #normalize data 3 using minmax 3\n",
        "        normalize_dataset(pdata,minmax3)\n",
        "\n",
        "        r3 = list()\n",
        "\n",
        "        for i in pdata:\n",
        "        \tk = predict(network,i)\n",
        "        \tr3.append(k)\n",
        "        r = r3\n",
        "        print(r3)\n",
        "    else:\n",
        "        print(predict(network,h))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbHtq6MkjJ6l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "outputId": "bfb1ad7e-e353-4cdc-b0a8-e427f6be2395"
      },
      "source": [
        "main()\n",
        "\n",
        "s = list()\n",
        "dataset = pd.read_csv(a)\n",
        "dataset.drop(dataset.columns[[1,2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]], axis = 1, inplace = True)\n",
        "\n",
        "dataset['final_results'] = r\n",
        "dataset['final_results'] = dataset['final_results'].replace(1,\"pass\")\n",
        "dataset['final_results'] = dataset['final_results'].replace(0,\"fail\")\n",
        "f = ['need to do hardwork','improve presentation skills','have to study more']\n",
        "\n",
        "for i in r:\n",
        "    if  i == 1:\n",
        "        s.append('no suggestions')\n",
        "    else:\n",
        "        s.append(f[math.floor(random()*len(f))])\n",
        "\n",
        "dataset.insert(3,'SUGG', s, True)\n",
        "print(dataset)\n",
        "print('\\n\\t*** result is also availabe in results folder ***')\n",
        "dataset.to_csv('results/result.csv')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enter the choice \n",
            "0) predicting for more.\n",
            "1) predicting for a single.\n",
            "\n",
            "   0\n",
            "enter the file name for predicting:predictData.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training model:   0%|           [time left: 03:49 ]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "building phase1 model:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training model: 100%|██████████ [time left: 00:00 ]\n",
            "testing model : 100%|██████████ [time left: 00:00 ]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "scores: [90.74250811223516, 91.1910669975186]\n",
            "mean Acuracy: 90.967%\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "enter c to continue or enter x to exit\n",
            "\tx\n",
            "   Course_code  Student_id final_results            SUGG\n",
            "0     10A70501  10341A0582          pass  no suggestions\n",
            "1     10A70501  11341A0573          pass  no suggestions\n",
            "2     10A70501  11341A0574          pass  no suggestions\n",
            "3     10A70501  11341A0576          pass  no suggestions\n",
            "4     10A70501  11341A0577          pass  no suggestions\n",
            "5     10A70501  11341A0578          pass  no suggestions\n",
            "6     10A70501  11341A0579          pass  no suggestions\n",
            "7     10A70501  11341A0580          pass  no suggestions\n",
            "8     10A70501  11341A0581          pass  no suggestions\n",
            "9     10A70501  11341A0582          pass  no suggestions\n",
            "10    10A70501  11341A0583          pass  no suggestions\n",
            "11    10A70501  11341A0584          pass  no suggestions\n",
            "12    10A70501  11341A0585          pass  no suggestions\n",
            "13    10A70501  11341A0586          pass  no suggestions\n",
            "14    10A70501  11341A0587          pass  no suggestions\n",
            "15    10A70501  11341A0588          pass  no suggestions\n",
            "\n",
            "\t*** result is also availabe in results folder ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e7d6f11d18c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\t*** result is also availabe in results folder ***'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/result.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/result.csv'"
          ]
        }
      ]
    }
  ]
}